{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definição da classe Perceptron\n",
    "\n",
    "A classe Perceptron é uma implementação das formas mais simples de um classificador linear. Este modelo é baseado no conceito de um neurônio artificial e é capaz de realizar classificações binárias. A classe consiste em várias partes principais:\n",
    "\n",
    "**weights**: Lista que armazena os pesos associados a cada entrada, onde cada peso determina a importância de cada entrada na decisão.\n",
    "\n",
    "**threshold**: Número de iterações sobre o conjunto de treinamento para ajustar os pesos.\n",
    "\n",
    "**learning_rate**: Taxa de aprendizado que controla o quanto os pesos são ajustados durante o treinamento.\n",
    "\n",
    "**bias**: Coeficiente da dimensão Y da formula linear utilizada no perceptron\n",
    "\n",
    "\n",
    "A predição é feita realizando o somatorio dos pesos multiplicados pelas entradas + o bias, o que pode ser simplificado na formula da equação linear sum(wx)+b\n",
    "\n",
    "Por fim o treinamento é feito com a iteração entre os valores de treinamento, para cada valor de entrada se realiza a predição, e com base no erro os pesos são ajustados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    weights = 0\n",
    "    threshold = 0\n",
    "    learning_rate = 0\n",
    "    bias = 0\n",
    "    \n",
    "    def __init__(self, num_inputs, threshold=100000, learning_rate=0.01):\n",
    "        # Inicializando os pesos e o bias\n",
    "        self.weights = [0.0 for _ in range(num_inputs)]\n",
    "        self.bias = 0.0\n",
    "        self.threshold = threshold\n",
    "        self.learning_rate = learning_rate\n",
    "    \n",
    "    def predict(self, inputs):\n",
    "        # Calcula a soma ponderada das entradas e adiciona o bias\n",
    "        summation = sum(w * i for w, i in zip(self.weights, inputs)) + self.bias\n",
    "        # Aplica a função de ativação (step function)\n",
    "        return 1 if summation > 0 else 0\n",
    "    \n",
    "    def train(self, training_inputs, labels):\n",
    "        for _ in range(self.threshold):\n",
    "            for inputs, label in zip(training_inputs, labels):\n",
    "                prediction = self.predict(inputs)\n",
    "                # Ajusta os pesos e o bias com base no erro (label - prediction)\n",
    "                for i in range(len(self.weights)):\n",
    "                    self.weights[i] += self.learning_rate * (label - prediction) * inputs[i]\n",
    "                self.bias += self.learning_rate * (label - prediction)\n",
    "\n",
    "    def print_formula(self):\n",
    "        terms = [f\"({w:.2f} * x{i})\" for i, w in enumerate(self.weights, start=1)]\n",
    "        formula = \" + \".join(terms) + f\" + {self.bias:.2f}\"\n",
    "        print(f\"\\nformula = {formula}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geração automatica de inputs com todas as combinações possiveis de valores de 0 e 1 dentro o tamanho especificado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_inputs(n):\n",
    "    return [[(i >> j) & 1 for j in range(n)] for i in range(2 ** n)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encapsulamento da logica de geração entre AND e OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_perceptron(n, function_type):\n",
    "    inputs = generate_inputs(n)\n",
    "    if function_type == 'AND':\n",
    "        labels = [1 if all(inp) else 0 for inp in inputs]\n",
    "    elif function_type == 'OR':\n",
    "        labels = [1 if any(inp) else 0 for inp in inputs]\n",
    "    else:\n",
    "        raise ValueError(\"Function type must be 'AND' or 'OR'\")\n",
    "    \n",
    "    perceptron = Perceptron(num_inputs=n)\n",
    "    perceptron.train(inputs, labels)\n",
    "    \n",
    "    return perceptron, inputs, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encapsulamento da logica de teste e validação do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_perceptron(perceptron, inputs, labels):\n",
    "    correct_predictions = 0\n",
    "    for inp, label in zip(inputs, labels):\n",
    "        prediction = perceptron.predict(inp)\n",
    "        if prediction == label:\n",
    "            correct_predictions += 1\n",
    "        print(f\"Input: {inp} - Expected: {label}, Predicted: {prediction}\")\n",
    "    \n",
    "    print(f\"\\nAccuracy: {correct_predictions / len(inputs) * 100}%\")\n",
    "    return correct_predictions / len(inputs) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_perceptron_xor(n):\n",
    "    inputs = generate_inputs(n)\n",
    "    labels = [1 if sum(inp) % 2 != 0 else 0 for inp in inputs]\n",
    "    \n",
    "    perceptron = Perceptron(num_inputs=n)\n",
    "    perceptron.train(inputs, labels)\n",
    "    \n",
    "    return perceptron, inputs, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinar e testar o Perceptron para a função AND com 2 entradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [0, 0] - Expected: 0, Predicted: 0\n",
      "Input: [1, 0] - Expected: 0, Predicted: 0\n",
      "Input: [0, 1] - Expected: 0, Predicted: 0\n",
      "Input: [1, 1] - Expected: 1, Predicted: 1\n",
      "\n",
      "Accuracy: 100.0%\n",
      "\n",
      "formula = (0.01 * x1) + (0.02 * x2) + -0.02\n"
     ]
    }
   ],
   "source": [
    "perceptron_and, inputs_and, labels_and = train_perceptron(2, 'AND')\n",
    "test_perceptron(perceptron_and, inputs_and, labels_and)\n",
    "perceptron_and.print_formula()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [0, 0] - Expected: 0, Predicted: 0\n",
      "Input: [1, 0] - Expected: 1, Predicted: 1\n",
      "Input: [0, 1] - Expected: 1, Predicted: 1\n",
      "Input: [1, 1] - Expected: 1, Predicted: 1\n",
      "\n",
      "Accuracy: 100.0%\n",
      "\n",
      "formula = (0.01 * x1) + (0.01 * x2) + 0.00\n"
     ]
    }
   ],
   "source": [
    "perceptron_and, inputs_and, labels_and = train_perceptron(2, 'OR')\n",
    "test_perceptron(perceptron_and, inputs_and, labels_and)\n",
    "perceptron_and.print_formula()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinar e testar o Perceptron para a função XOR com 2 entradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [0, 0] - Expected: 0, Predicted: 1\n",
      "Input: [1, 0] - Expected: 1, Predicted: 1\n",
      "Input: [0, 1] - Expected: 1, Predicted: 0\n",
      "Input: [1, 1] - Expected: 0, Predicted: 0\n",
      "\n",
      "Accuracy: 50.0%\n",
      "\n",
      "formula = (0.00 * x1) + (-0.01 * x2) + 0.01\n"
     ]
    }
   ],
   "source": [
    "perceptron_xor, inputs_xor, labels_xor = train_perceptron_xor(2)\n",
    "test_perceptron(perceptron_xor, inputs_xor, labels_xor)\n",
    "perceptron_xor.print_formula()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
